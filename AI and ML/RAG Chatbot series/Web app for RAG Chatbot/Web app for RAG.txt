##1 Create S3 bucket and Knowledge Base

##2 Run AWS Command

# Configure AWS CLI in terminal to log in

Run aws configure 
Enter your Access Key, Secret Key, region (e.g. us-east-2), and output format (json)

Set Up AWS Access Keys

Users-> IAM Admin user -> Security credentials -> Access keys section -> Create access key

##3 Cloning the repository

cd %USERPROFILE%\Documents or respective directory prefer 

git clone [HTTPS-URL]

(Git install if not available) 

# Navigate to the Project Directory

cd nextwork-rag-webapp

# Create Your Virtual Environment

python -m venv venv

( Install Python and pip if not to check the availabity run python --version and pip -- version )

# Activate your virtual environment:

.\venv\Scripts\activate

To verify that your virtual environment is activated, run:

echo $env:VIRTUAL_ENV

## Test the Backend 

To run the API:

python -m uvicorn main:app --reload

# Install Requirements

ERROR ModuleNotFoundError: No module named uvicorn


cat requirements.txt

pip3 install -r requirements.txt

pip3 list


Re-run the API 

python -m uvicorn main:app --reload

Visit the Root Endpoint-> http://127.0.0.1:8000

##4 Run the Query Endpoint

- Ask your chatbot a question over the API (using the query endpoint)
- Troubleshoot errors in your API setup.

Visit the Query Endpoint
Update the URL in your browser to:- This asks your chatbot "What is NextWork?"

 http://127.0.0.1:8000/bedrock/query?text=What%20is%20NextWork.

 
If you see an error message for Invalid type for parameter related to your knowledgeBaseId or modelArn, it means that your API isn't correctly configured with your Knowledge Base ID and Model ARN.


# Finding Your Knowledge Base and Model ARN & IDs

1) Find the Knowledge Base ID from the overview panel.
2) Find Your Model ARN

In the CloudShell terminal, run the following command to find the ARN of your model.

aws bedrock get-foundation-model --model-identifier <your-model-id>
 
To find Model ID, Open Bedrock console again 
 - Select Model catalog
 - where you can find all the models available in Bedrock, and find metadata about each model - like the Model ID.
 - Find the Llama 3.3 70B Instruct model.
 - Copy the Model ID from the details panel
 

# Add Environment Variables

To fix the error in our API, we need to set our KNOWLEDGE_BASE_ID and MODEL_ARN as environment variables.

Ctrl + C 

Create a new .env file in your project directory:

New-Item .env
notepad .env

Telling our API the environment values we want it to use:

AWS_REGION=us-east-2
KNOWLEDGE_BASE_ID=<your_knowledge_base_id>
MODEL_ARN=<your_model_arn>

Replace the placeholders

Select File > Save

# Verify Environment Variables

cat .env

# Run Your API Again

python -m uvicorn main:app --reload

Test API by query endpoint http://127.0.0.1:8000/bedrock/query?text=What%20is%20NextWork


##5 Running the web app

- Run the web app using uvicorn with web_app.py
- Access the web app in your browser and interact with the chatbot
- Add the MODEL_ID environment variable to your .env file
- Test how the chatbot's responses change based on whether RAG is enabled or not

#Run web app 

python -m uvicorn web_app:app --reload

Go to the same URL as before (usually http://127.0.0.1:8000) 

Instead of just seeing a JSON message a full web app interface!

# Test the Chatbot
- Select Chat with my project 
- ASK question it will respond 

# Experiment with "Talk to AI directly"

- Check the Talk to AI directly checkbox below the chat input box.
- Ask same question again 500 Internal Server Error 

ERROR {"detail":"Model ID is missing"}

Add MODEL_ID to .env File

Ctrl + C to stop API server 

Add Model_ID to .env by 

notepad .env 
Select File > Save

Verify Environment Variables 
cat .env

#Restart the web app

python -m uvicorn web_app:app --reload

- Chat with projects check Talk to AI directly checkbox
- Ask same question SUCCESS!!!

##6 Customizing the Web App (Secret Mission)

-Use a ChatGPT prompt to generate a new HTML file or modify the existing index.html
-Integrate the generated HTML into your project
-Test your customized web app

# Create new index.html with ChatGPT

Make sure to attach the original index.html and style.css files to the prompt

PROMPT: At prompt file


# Integrate Generated HTML

Update index.html with ChatGPT's code. Make sure to save it 

# Test Customized web app

-Test it out by sending messages and interacting with the chatbot. Make sure all the features

##7 Delete the resources 

- Bedrock Knowledge Base
- OpenSearch Serverless collection (vector store)
- S3 bucket
- IAM access key
- Deactivate the virtual environment and delete your cloned repository